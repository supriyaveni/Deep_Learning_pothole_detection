# -*- coding: utf-8 -*-
"""DL MINI FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yidzs9hrbkpOS7Xd1lek5avAJ8vhV0OJ
"""

!pip install kaggle

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
upoladed = files.upload()

!chmod 600 ~/.kaggle/kaggle.json

import os
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

os.environ["KAGGLE_KEY"]  = "bbb6045a74cc0c9028dfb9004691defc"
os.environ["KAGGLE_USERNAME"]= "varshinilogu"

!kaggle datasets list

!kaggle datasets download -d atulyakumar98/pothole-detection-dataset

!unzip "/content/pothole-detection-dataset.zip"

import numpy as np # linear algebra
import os # operating system

from keras.utils import set_random_seed
set_random_seed(812)

import cv2
import matplotlib.pyplot as plt

def explore_dir(dir_path, count):
    for _, _, filenames in os.walk(dir_path):
        for i in range(count):
            img = cv2.imread(os.path.join(dir_path, filenames[i]))
            plt.imshow(img)
            plt.show()

normal_dir = '/content/normal'
potholes_dir = '/content/potholes'

explore_dir(normal_dir, 3)
explore_dir(potholes_dir, 3)

def count_files(dir_path):
    file_count = 0
    for _, _, filenames in os.walk(dir_path):
        file_count += len(filenames)
    return file_count

print('Normal images: ', count_files(normal_dir))
print('Potholes images: ', count_files(potholes_dir))

desired_size = (150, 150)
X, Y = [], []

def add_images(dir_path, label):
    for _, _, filenames in os.walk(dir_path):
        for file in filenames:
            try:
                img = cv2.imread(os.path.join(dir_path, file))
                img = cv2.resize(img, desired_size)
                X.append(np.array(img))
                Y.append(label)
            except:
                print('Image ' + os.path.join(dir_path, file) + ' could not be resized')

add_images(normal_dir, 0)
add_images(potholes_dir, 1)

print(f"Dataset size: X = {len(X)}, Y = {len(Y)}")

import tensorflow as tf

img_count = len(X)
for i in range(img_count):
    flipped = tf.image.flip_left_right(X[i])
    X.append(flipped)
    Y.append(Y[i])
print(img_count)

to_visualize = 3

for i in range(to_visualize):
    plt.subplot(1, 2, 1).imshow(X[i])
    plt.title('Original')
    plt.subplot(1, 2, 2).imshow(X[img_count + i])
    plt.title('Flipped')
    plt.show()

from keras.utils import to_categorical

Y = to_categorical(Y,2)
print(Y)

from sklearn.model_selection import train_test_split

X = np.array(X)
x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.20, random_state=5)

print(x_train.shape)
print(x_test.shape)

"""**ANN**"""

from tensorflow.keras import datasets, models
from tensorflow.keras.layers import Flatten, Dense, Dropout

ann = models.Sequential([
    Flatten(input_shape=(150, 150, 3)),
    Dense(100, activation='relu'),
    Dense(150, activation='relu'),
    Dense(150, activation='relu'),
    Dense(150, activation='relu'),
    Dense(100, activation='relu'),
    Dropout(0.15),
    Dense(2, activation = 'softmax')
])

# print model's architecture
ann.summary()

from keras.optimizers import Adam
from keras.callbacks import EarlyStopping

ann.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])

es = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)

history = ann.fit(x_train, y_train, epochs=30, batch_size=32,
                    validation_data=(x_test, y_test))

# plot the training history
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

from sklearn.metrics import roc_curve, auc
y_true_labels = y_test[:,1]

# Obtain predicted probabilities for the positive class
y_pred_prob = ann.predict(x_test)[:, 1]

# Compute ROC curve and ROC area
fpr, tpr, _ = roc_curve(y_true_labels, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# Assuming `history` is the History object returned by `model.fit()`
plt.figure()
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Cross-Entropy Loss During Training')
plt.legend()
plt.show()

# print the achieved accuracy
ann_test_loss, ann_test_acc = ann.evaluate(x_test, y_test, verbose=2)
print('Best accuracy: ', ann_test_acc)

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Obtain predicted labels for test set
y_pred = ann.predict(x_test)
y_pred_labels = np.argmax(y_pred, axis=1)
y_true_labels = np.argmax(y_test, axis=1)

# Calculate confusion matrix
conf_mat = confusion_matrix(y_true_labels, y_pred_labels)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Class 0', 'Class 1'],
            yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

"""**CNN**"""

from tensorflow.keras import datasets, models
from tensorflow.keras.layers import Conv2D, MaxPooling2D

cnn = models.Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.15),
    Dense(2, activation='softmax')
])

# print model's architecture
cnn.summary()

es = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)

cnn.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])

history = cnn.fit(x_train, y_train, epochs=20, batch_size=32,
                    validation_data=(x_test, y_test))

# plot the training history
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

# Obtain predicted labels for test set
y_pred_cnn = cnn.predict(x_test)
y_pred_labels_cnn = np.argmax(y_pred_cnn, axis=1)
y_true_labels_cnn = np.argmax(y_test, axis=1)

# Calculate confusion matrix
conf_mat_cnn = confusion_matrix(y_true_labels_cnn, y_pred_labels_cnn)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat_cnn, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Class 0', 'Class 1'],
            yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix (CNN)')
plt.show()

# Obtain predicted probabilities for the positive class
y_pred_prob_cnn = cnn.predict(x_test)[:, 1]

# Compute ROC curve and ROC area
fpr_cnn, tpr_cnn, _ = roc_curve(y_true_labels_cnn, y_pred_prob_cnn)
roc_auc_cnn = auc(fpr_cnn, tpr_cnn)

# Plot ROC curve
plt.figure()
plt.plot(fpr_cnn, tpr_cnn, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_cnn:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (CNN)')
plt.legend(loc='lower right')
plt.show()

# Assuming `cnn_history` is the History object returned by `cnn.fit()`
plt.figure()
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Cross-Entropy Loss During Training (CNN)')
plt.legend()
plt.show()

# print the achieved accuracy
cnn_test_loss, cnn_test_acc = cnn.evaluate(x_test,  y_test, verbose=2)
print('Best accuracy: ', cnn_test_acc)

"""**INCEPTION** **V3**"""

from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
from tensorflow.keras.layers import GlobalAveragePooling2D

# load the base model without the top layer: we will add ours for fine-tuning
base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

# create the model: we will add the necessary layers for our task on top of the base model
inception = models.Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),
    Dense(256, activation='relu'),
    Dropout(0.25),
    Dense(2, activation='softmax')
])


# we will only train the top layers, i.e. the ones we added
# thus, we need to freeze all the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

inception.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# pre-process the data to meet InceptionV3 requirements
x_train_inception = preprocess_input(x_train)
x_test_inception = preprocess_input(x_test)


# train the model on the new data for a few epochs
history = inception.fit(x_train_inception, y_train, epochs=20,
                    validation_data=(x_test_inception, y_test))

# plot the training history
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

# Obtain predicted labels for test set
y_pred_inception = inception.predict(x_test_inception)
y_pred_labels_inception = np.argmax(y_pred_inception, axis=1)
y_true_labels_inception = np.argmax(y_test, axis=1)

# Calculate confusion matrix
conf_mat_inception = confusion_matrix(y_true_labels_inception, y_pred_labels_inception)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat_inception, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Class 0', 'Class 1'],
            yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix (InceptionV3)')
plt.show()

# Obtain predicted probabilities for the positive class
y_pred_prob_inception = inception.predict(x_test_inception)[:, 1]

# Compute ROC curve and ROC area
fpr_inception, tpr_inception, _ = roc_curve(y_true_labels_inception, y_pred_prob_inception)
roc_auc_inception = auc(fpr_inception, tpr_inception)

# Plot ROC curve
plt.figure()
plt.plot(fpr_inception, tpr_inception, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_inception:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (InceptionV3)')
plt.legend(loc='lower right')
plt.show()

# Assuming `inception_history` is the History object returned by `inception.fit()`
plt.figure()
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Cross-Entropy Loss During Training (InceptionV3)')
plt.legend()
plt.show()

# print the achieved accuracy
inception_test_loss, inception_test_acc = inception.evaluate(x_test_inception,  y_test, verbose=2)
print('Best accuracy: ', inception_test_acc)



"""**RESNET50**"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.25),
    layers.Dense(2, activation='softmax')  # Use 'sigmoid' if it's a binary classification problem
])

for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

x_train_resnet = preprocess_input(x_train)
x_test_resnet = preprocess_input(x_test)

history = model.fit(x_train_resnet, y_train, epochs=10,
                    validation_data=(x_test_resnet, y_test))

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

y_pred_resnet = model.predict(x_test_resnet)
y_pred_labels_resnet = np.argmax(y_pred_resnet, axis=1)
y_true_labels_resnet = np.argmax(y_test, axis=1)
conf_mat_resnet = confusion_matrix(y_true_labels_resnet, y_pred_labels_resnet)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat_resnet, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Class 0', 'Class 1'],
            yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix (ResNet50)')
plt.show()

# Obtain predicted probabilities for the positive class using ResNet50
y_pred_prob_resnet = model.predict(x_test_resnet)[:, 1]

# Compute ROC curve and ROC area for ResNet50
fpr_resnet, tpr_resnet, _ = roc_curve(y_true_labels_resnet, y_pred_prob_resnet)
roc_auc_resnet = auc(fpr_resnet, tpr_resnet)
plt.figure()
plt.plot(fpr_resnet, tpr_resnet, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_resnet:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (ResNet50)')
plt.legend(loc='lower right')
plt.show()

# Assuming `resnet_history` is the History object returned by `resnet.fit()`
plt.figure()
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Cross-Entropy Loss During Training (ResNet50)')
plt.legend()
plt.show()

# print the achieved accuracy
# Evaluate ResNet50 model
resnet_test_loss, resnet_test_acc = model.evaluate(x_test_resnet, y_test, verbose=2)
print('ResNet50 Test Accuracy: ', resnet_test_acc)

"""**EfficientNetB0**"""

import tensorflow as tf
from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),  # Adjusted for compatibility with EfficientNetB0
    Dense(256, activation='relu'),   # Adjusted for compatibility with EfficientNetB0
    Dropout(0.25),
    Dense(2, activation='softmax')   # Number of classes should match your dataset
])

for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

x_train_efficientnet = preprocess_input(x_train)
x_test_efficientnet = preprocess_input(x_test)

history = model.fit(x_train_efficientnet, y_train, epochs=20,
                    validation_data=(x_test_efficientnet, y_test))

# Plot the training history
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

# Obtain predicted labels for the test set using EfficientNetB0
y_pred_efficientnet = model.predict(x_test_efficientnet)
y_pred_labels_efficientnet = np.argmax(y_pred_efficientnet, axis=1)
y_true_labels_efficientnet = np.argmax(y_test, axis=1)

# Calculate the confusion matrix for EfficientNetB0
conf_mat_efficientnet = confusion_matrix(y_true_labels_efficientnet, y_pred_labels_efficientnet)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat_efficientnet, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Class 0', 'Class 1'],
            yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix (EfficientNetB0)')
plt.show()

# Obtain predicted probabilities for the positive class using EfficientNetB0
y_pred_prob_efficientnet = model.predict(x_test_efficientnet)[:, 1]

# Compute ROC curve and ROC area for EfficientNetB0
fpr_efficientnet, tpr_efficientnet, _ = roc_curve(y_true_labels_efficientnet, y_pred_prob_efficientnet)
roc_auc_efficientnet = auc(fpr_efficientnet, tpr_efficientnet)
plt.figure()
plt.plot(fpr_efficientnet, tpr_efficientnet, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_efficientnet:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (EfficientNetB0)')
plt.legend(loc='lower right')
plt.show()

# Assuming `efficientnet_b0_history` is the History object returned by `efficientnet_b0.fit()`
plt.figure()
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Cross-Entropy Loss During Training (EfficientNetB0)')
plt.legend()
plt.show()

# Evaluate EfficientNetB0 model
efficientnet_b0_test_loss, efficientnet_b0_test_acc = model.evaluate(x_test_efficientnet, y_test, verbose=2)
print('EfficientNetB0 Test Accuracy: ', efficientnet_b0_test_acc)

import matplotlib.pyplot as plt

# Accuracy values for each model
accuracy_values = {
    "ANN": 0.779411792755127,
    "CNN": 0.970588207244873,
    "InceptionV3": 0.845588207244873,
    "ResNet50": 0.845588207244873,
}

# Names of the models
model_names = ["ANN", "CNN", "InceptionV3", "ResNet50"]

# Create bar chart
plt.figure(figsize=(10, 6))
plt.bar(model_names, accuracy_values.values(), color=['blue', 'green', 'red', 'purple'])

# Add labels and title
plt.xlabel('Model Name')
plt.ylabel('Accuracy')
plt.title('Comparison of Model Accuracies')

# Show the plot
plt.show()